% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model_validation.R
\name{run_validation}
\alias{run_validation}
\title{Run EPIDEMIA model validation statistics}
\usage{
run_validation(week_start = NULL, total_weeks = 12, weeks_ahead = 2,
  skill_test = FALSE, epi_data = NULL, casefield = NULL,
  populationfield = NULL, groupfield = NULL, week_type = c("ISO",
  "CDC"), report_period = 3, ed_summary_period = 1,
  ed_method = "none", env_data = NULL, obsfield = NULL,
  valuefield = NULL, forecast_future = 2, fc_control = NULL,
  env_ref_data = NULL, env_info = NULL, model_cached = NULL,
  model_choice = c("poisson-bam", "negbin"), ...)
}
\arguments{
\item{week_start}{Date to start testing for model validation.}

\item{total_weeks}{Number of weeks from `week_start` to run validation tests.}

\item{weeks_ahead}{Number of weeks for testing the n-week ahead forecasts.
Results will be generated from 1-week ahead through `weeks_ahead` number of
weeks.}

\item{skill_test}{Logical parameter indicating whether or not to run
validations also on two naïve models for a skill test comparison. The naïve
models are "persistence": the last known value (case counts) carried
forward, and "average week" where the predicted value is the average of that
week of the year, as calculated from historical data.}

\item{epi_data}{See description in `run_epidemia()`.}

\item{casefield}{See description in `run_epidemia()`.}

\item{populationfield}{See description in `run_epidemia()`.}

\item{groupfield}{See description in `run_epidemia()`.}

\item{week_type}{See description in `run_epidemia()`.}

\item{report_period}{The number of weeks that the entire report will cover.
The \code{report_period} minus \code{forecast_future} is the number of weeks
of past (known) data that will be included. Overwritten to be `weeks_ahead`
+ 1 for validation runs.}

\item{ed_summary_period}{Overwritten to 1 for validation runs (no-op for no
event detection during validation runs).}

\item{ed_method}{Overwritten to "none" for validation runs.}

\item{env_data}{See description in `run_epidemia()`.}

\item{obsfield}{See description in `run_epidemia()`.}

\item{valuefield}{See description in `run_epidemia()`.}

\item{forecast_future}{Number of future weeks from the end of the
\code{epi_data} to produce forecasts, as in `run_epidemia()`, but
overwritten as `weeks_ahead` for validation runs.}

\item{fc_control}{See description in `run_epidemia()`. Note,
fc_control$value_type is overwritten as "cases" for validation runs.}

\item{env_ref_data}{See description in `run_epidemia()`.}

\item{env_info}{See description in `run_epidemia()`.}

\item{model_cached}{See description in `run_epidemia()`.}

\item{model_choice}{See description in `run_epidemia()`.}

\item{...}{Accepts other arguments that are normally part of `run_epidemia()`,
but ignored for validation runs. For example, `inc_per`, `ed_control`,
`model_run`.}
}
\value{
Returns a list of validation statistics. Statistics are calculated on
 the n-week ahead forecast and the actual observed case counts. Statistics
 returned are Mean Squared Error (MSE), Mean Absolute Error (MAE), and
 proportion of observed values that were inside the prediction interval
 (prop_interval). The first object `validation_overall` is the results
 overall, and `validation_grouping` is the results per geographic grouping.
}
\description{
This function takes a few more arguments than `epidemiar::run_epidemia()` to
generate statistics on model validation. The function will evaluate a number
of weeks (`total_weeks`) starting from a specified week (`week_start`) and
will look at the n-week ahead forecast (1 to `weeks_ahead` number of weeks)
and compare the values to the observed number of cases. The validation
statistics include Mean Squared Error (MSE) and Mean Absolute Error (MAE),
both in total and per geographic grouping (if present).
}
